{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Disaster Tweet Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Kevin Guo, Pranav Sriram, Raymond Yao\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "#from datasets import train_test_split\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_name = 'bert-base-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_phi(text):\n",
    "    input_ids = bert_tokenizer.encode(text, add_special_tokens=True)\n",
    "    X = torch.tensor([input_ids])\n",
    "    with torch.no_grad():\n",
    "        reps = bert_model(X)\n",
    "        return reps.last_hidden_state.squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_classifier_phi(text):\n",
    "    reps = bert_phi(text)\n",
    "    #return reps.mean(axis=0)  # Another good, easy option.\n",
    "    return reps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('real_and_fake_news.csv')\n",
    "all_data['text'] = all_data['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "relevant_data, unneeded = np.split(all_data.sample(frac=1, random_state=42), [10000])\n",
    "train, dev, test = np.split(relevant_data, [int(.8*len(relevant_data)), int(.9*len(relevant_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "30464   Obama Announces ‘Unfinished Business’ For 201...      0\n",
      "41926  IT BEGINS….OBAMA APPOINTED JUDGE Rules Trump U...      0\n",
      "8877   White House says Obama will not discuss FBI pr...      1\n",
      "3798   Treasury unit to share records with Senate for...      1\n",
      "39671  HOLLYWOOD LIBS HAVE EPIC MELT DOWNS…Threaten P...      0\n",
      "...                                                  ...    ...\n",
      "22636   Republicans Dine With Trump, Then Try To Rail...      0\n",
      "2622   Trump Jr., Manafort agree to negotiate over in...      1\n",
      "6334   After 2016 campaign, more Americans consider R...      1\n",
      "1801   US Senate may vote this week to add penalties ...      1\n",
      "20427  FPL shuts one reactor in Florida, reduces powe...      1\n",
      "\n",
      "[8000 rows x 2 columns]\n",
      "                                                    text  label\n",
      "34238  WILL HILLARY ATTEND? ‘CLOWN LIVES MATTER’ Rall...      0\n",
      "13316  Bosnian Croat war criminal Praljak killed hims...      1\n",
      "14057  U.S. ally seen clinching re-election in Hondur...      1\n",
      "38775  A MUST SEE! THE BALTIMORE RIOT STORY IN ONE BI...      0\n",
      "10653  Puerto Rico needs restructuring to avoid casca...      1\n",
      "...                                                  ...    ...\n",
      "15747  Funeral of slain Malta blogger hears warning t...      1\n",
      "4068   Trump proposes 15 percent business tax rate: W...      1\n",
      "30235   Jealous Donald Trump Attacks Megyn Kelly Agai...      0\n",
      "25317   White Grievance Queen Tomi Lahren Gets OWNED ...      0\n",
      "15273  Prospects for Putin-Trump meeting at APEC summ...      1\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                                    text  label\n",
      "44221        What a Wonderful World – US Saviour Complex      0\n",
      "25388   Obama Just OBLITERATED The GOP’s Threat To Ki...      0\n",
      "22701   Trump Immediately Politicizes London Tragedy ...      0\n",
      "17542  Nigeria jails 45 Boko Haram suspects in mass t...      1\n",
      "43009  OBAMA COZIES UP TO ANOTHER COMMUNIST LEADER TO...      0\n",
      "...                                                  ...    ...\n",
      "41841  SYRIAN IMMIGRANT Who Said “9-11 Changed The Wo...      0\n",
      "38962  OOPS! Lindsey Vonn Gets Hit With Big Dose Of K...      0\n",
      "9211   U.S. top court deals blow to Puerto Rico sover...      1\n",
      "19438  EU officials reach draft deal on more North Ko...      1\n",
      "2592   Trump aide Greenblatt heading to Jordan for ta...      1\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(dev)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "X_str_train = train.text.values\n",
    "print(len(X_str_train))\n",
    "y_train = train.label.values\n",
    "\n",
    "X_str_dev = dev.text.values\n",
    "print(len(X_str_dev))\n",
    "y_dev = dev.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 19s, sys: 7.72 s, total: 20min 27s\n",
      "Wall time: 20min 20s\n"
     ]
    }
   ],
   "source": [
    "%time X_train = [bert_classifier_phi(text) for text in X_str_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 753 ms, total: 2min 31s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%time X_dev = [bert_classifier_phi(text) for text in X_str_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchShallowNeuralClassifier(\n",
    "    early_stopping=True,\n",
    "    hidden_dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 23. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.08604448172263801"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.03 s, sys: 138 ms, total: 6.17 s\n",
      "Wall time: 5.83 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.994     1.000     0.997       514\n",
      "           1      1.000     0.994     0.997       486\n",
      "\n",
      "    accuracy                          0.997      1000\n",
      "   macro avg      0.997     0.997     0.997      1000\n",
      "weighted avg      0.997     0.997     0.997      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_dev, preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_pickle('intermediate_model')\n",
    "#model.save_pretrained('int_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = TorchShallowNeuralClassifier(\n",
    "    early_stopping=True,\n",
    "    hidden_dim=300)\n",
    "new_model = new_model.from_pickle('intermediate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchShallowNeuralClassifier(\n",
      "\tbatch_size=1028,\n",
      "\tmax_iter=1000,\n",
      "\teta=0.001,\n",
      "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
      "\tl2_strength=0,\n",
      "\tgradient_accumulation_steps=1,\n",
      "\tmax_grad_norm=None,\n",
      "\tvalidation_fraction=0.1,\n",
      "\tearly_stopping=True,\n",
      "\tn_iter_no_change=10,\n",
      "\twarm_start=False,\n",
      "\ttol=1e-05,\n",
      "\thidden_dim=300,\n",
      "\thidden_activation=Tanh())\n"
     ]
    }
   ],
   "source": [
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_size', 'max_iter', 'eta', 'optimizer_class', 'l2_strength', 'gradient_accumulation_steps', 'max_grad_norm', 'validation_fraction', 'early_stopping', 'n_iter_no_change', 'warm_start', 'tol', 'hidden_dim', 'hidden_activation']\n"
     ]
    }
   ],
   "source": [
    "print(new_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_data = pd.read_csv('tweets_mod_copy.csv')\n",
    "second_data['text'] = second_data['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "second_train, second_dev, second_test = np.split(second_data.sample(frac=1, random_state=42), [int(.8*len(second_data)), int(.9*len(second_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "3495   How many illegal buildings should be demolishe...       0\n",
      "5461                     Who’s fatality is this tho ????       0\n",
      "9794   #OnThisDay 2018 Chinese state media confirmed ...       1\n",
      "11105  With any luck you will miss the windstorm on e...       0\n",
      "1803   Inferno on Black Friday 1939: 71 deaths, 3,700...       1\n",
      "...                                                  ...     ...\n",
      "2196   go ahead and make a playlist with your name. g...       0\n",
      "8561   Ruckelshaus, Sweeney and DDT – rescued from th...       0\n",
      "11236  😂We learned a long time ago why all major bank...       0\n",
      "4285   5,000 feral camels culled in drought-hit Austr...       1\n",
      "8569   Another rescued mumma koala with her little ne...       1\n",
      "\n",
      "[9096 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(second_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9096\n",
      "1137\n"
     ]
    }
   ],
   "source": [
    "second_X_str_train = second_train.text.values\n",
    "print(len(second_X_str_train))\n",
    "second_y_train = second_train.labels.values\n",
    "\n",
    "second_X_str_dev = second_dev.text.values\n",
    "print(len(second_X_str_dev))\n",
    "second_y_dev = second_dev.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24min 40s, sys: 8.04 s, total: 24min 48s\n",
      "Wall time: 24min 37s\n"
     ]
    }
   ],
   "source": [
    "%time second_X_train = [bert_classifier_phi(text) for text in second_X_str_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 3s, sys: 1.16 s, total: 3min 4s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%time second_X_dev = [bert_classifier_phi(text) for text in second_X_str_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model = new_model.from_pickle('intermediate_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 19. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 2.1667959690093994"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.64 s, sys: 105 ms, total: 5.74 s\n",
      "Wall time: 5.42 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = intermediate_model.fit(second_X_train, second_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_preds = intermediate_model.predict(second_X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     0.948     0.928       920\n",
      "           1      0.730     0.599     0.658       217\n",
      "\n",
      "    accuracy                          0.881      1137\n",
      "   macro avg      0.820     0.773     0.793      1137\n",
      "weighted avg      0.875     0.881     0.877      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_y_dev, second_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlu",
   "language": "python",
   "name": "nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
