{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a98620",
   "metadata": {},
   "source": [
    "# Final Project: Disaster Tweet Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570ff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Kevin Guo, Pranav Sriram, Raymond Yao\"\n",
    "__version__ = \"CS224u, Stanford, Spring 2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd55c6",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a24a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d60945db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "utils.fix_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8a6003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If this child was Chinese, this tweet would ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Several houses have been set ablaze in Ngemsib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asansol: A BJP office in Salanpur village was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>National Security Minister, Kan Dapaah's side ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This creature whoâ€™s soul is no longer clarent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n",
       "1  Telangana: Section 144 has been imposed in Bha...       1\n",
       "2  Arsonist sets cars ablaze at dealership https:...       1\n",
       "3  Arsonist sets cars ablaze at dealership https:...       1\n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0\n",
       "5  If this child was Chinese, this tweet would ha...       0\n",
       "6  Several houses have been set ablaze in Ngemsib...       1\n",
       "7  Asansol: A BJP office in Salanpur village was ...       1\n",
       "8  National Security Minister, Kan Dapaah's side ...       0\n",
       "9  This creature whoâ€™s soul is no longer clarent ...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_mod_copy.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484c3d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Telangana: Section 144 has been imposed in Bha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsonist sets cars ablaze at dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If this child was Chinese, this tweet would ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Several houses have been set ablaze in Ngemsib...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asansol: A BJP office in Salanpur village was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>National Security Minister, Kan Dapaah's side ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This creature whoâ€™s soul is no longer clarent ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n",
       "1  Telangana: Section 144 has been imposed in Bha...       1\n",
       "2           Arsonist sets cars ablaze at dealership        1\n",
       "3          Arsonist sets cars ablaze at dealership         1\n",
       "4  \"Lord Jesus, your love brings freedom and pard...       0\n",
       "5  If this child was Chinese, this tweet would ha...       0\n",
       "6  Several houses have been set ablaze in Ngemsib...       1\n",
       "7  Asansol: A BJP office in Salanpur village was ...       1\n",
       "8  National Security Minister, Kan Dapaah's side ...       0\n",
       "9  This creature whoâ€™s soul is no longer clarent ...       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove URLs\n",
    "df['text'] = df['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65625dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, dev, and test sets using a 80-10-10 ratio\n",
    "# train = df \n",
    "# dev = df\n",
    "# test = df\n",
    "train, dev, test = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int(.9*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936dea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = load_dataset('csv', data_files = 'tweets.csv')\n",
    "# dev_dataset = load_dataset('csv', data_files = 'tweets.csv')\n",
    "# test_dataset = load_dataset('csv', data_files = 'tweets.csv')\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "dev_dataset = Dataset.from_pandas(dev)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "# dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f2c68b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "# weights_name = 'bert-base-cased'\n",
    "# tokenizer = BertTokenizer.from_pretrained(weights_name)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "# x_train = train_dataset['text']\n",
    "# y_train = train_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c802e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fb67c8aa42493f8f3307f211eb4bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76acc5dcdbf14c99b97114a9af49b36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9afd78ab7d845b88eafcdf6de1323eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dev_dataset = dev_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"text\"])\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\")\n",
    "\n",
    "tokenized_dev_dataset.set_format(\"torch\")\n",
    "\n",
    "tokenized_test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55908a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"test_trainer\")\n",
    "\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boring-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_dev_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "939f3558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3411' max='3411' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3411/3411 1:23:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.113300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3411, training_loss=0.22191675007780148, metrics={'train_runtime': 5007.9302, 'train_samples_per_second': 0.681, 'total_flos': 9079642126172160, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "precise-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='143' max='143' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [143/143 01:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4116906523704529,\n",
       " 'eval_f1': 0.7634660421545667,\n",
       " 'eval_runtime': 71.9667,\n",
       " 'eval_samples_per_second': 15.799,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pregnant-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "specific-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = BertModel.from_pretrained('test_trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "35e6434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_phi(text):\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    X = torch.tensor([input_ids])\n",
    "    with torch.no_grad():\n",
    "        reps = finetuned_model(X)\n",
    "        return reps.last_hidden_state.squeeze(0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dbd7c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_classifier_phi(text):\n",
    "    reps = bert_phi(text)\n",
    "    #return reps.mean(axis=0)  # Another good, easy option.\n",
    "    return reps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "adjacent-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table = pd.read_table('2013_Queensland_Floods_train.tsv')\n",
    "train_table['text'] = train_table['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "\n",
    "dev_table = pd.read_table('2013_Queensland_Floods_dev.tsv')\n",
    "dev_table['text'] = dev_table['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "\n",
    "test_table = pd.read_table('2013_Queensland_Floods_test.tsv')\n",
    "test_table['text'] = test_table['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "\n",
    "\n",
    "train = train_table \n",
    "dev = dev_table \n",
    "test = test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cheap-ceremony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  label\n",
      "0     I just though about the night I went clubbing ...      0\n",
      "1     Looks like its going to be another long night ...      0\n",
      "2     @LaniiBanani hahahaha I just told him id have ...      0\n",
      "3     Off to meeting.... with so called... Baaps of ...      0\n",
      "4              Doubt I'll be getting much sleep tonight      0\n",
      "...                                                 ...    ...\n",
      "6014  RT @GrillTeam: The Queensland government has s...      1\n",
      "6015  Can we have 5 NEMA staff from Nigeria  come to...      1\n",
      "6016  RT @7NewsBrisbane: Foam from rough waves at Al...      1\n",
      "6017  RT @abcsouthqld: Master Electricians Australia...      1\n",
      "6018  RT @HomeLoanKing: Leader of Aussie opposition,...      1\n",
      "\n",
      "[6019 rows x 2 columns]\n",
      "                                                   text  label\n",
      "0     Fuck It.. Chelsea should have been all over Br...      0\n",
      "1     Hey Dana Does @Alistairovereem gets the title ...      0\n",
      "2     @mimstacey @janecaro game over. In most states...      0\n",
      "3     I just made a new word: Awkwul . A mix between...      0\n",
      "4     Nothing like stifling heat to make me want to ...      0\n",
      "...                                                 ...    ...\n",
      "998   Grafton Queensland Flood Peaks at 10.7 Meters:...      1\n",
      "999   Helicopters Deployed to Rescue Flood Victims i...      1\n",
      "1000  RT @maltesemanor: NO! we've suffered enough! M...      1\n",
      "1001  @skeletonunicorn the waters upto the door, my ...      1\n",
      "1002  Queensland's flood crisis deepens as death tol...      1\n",
      "\n",
      "[1003 rows x 2 columns]\n",
      "                                                   text  label\n",
      "0     @MarkSDobson I always thought that, big lad ai...      1\n",
      "1     @Maree_22 And this going to continue until tom...      1\n",
      "2     Room Available in Jacobs Ridge Ormeau $200.00 ...      1\n",
      "3     Dotti Size 6 Sailor/ Air Hostess / Japanese Sc...      1\n",
      "4     @Purpletiger79 I really enjoyed doing a photo ...      1\n",
      "...                                                 ...    ...\n",
      "3006  Thoughts go out to the flood victims of Queens...      1\n",
      "3007  #leimo  Keith Urban's Brisbane, Australia Conc...      1\n",
      "3008  RT @350: No end in sight for Australia flood v...      1\n",
      "3009  Queensland Treasurer Tim Nicholls spoke to Ste...      1\n",
      "3010  RT @GrillTeam: The Queensland government has s...      1\n",
      "\n",
      "[3011 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(dev)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "lovely-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6019\n",
      "1003\n"
     ]
    }
   ],
   "source": [
    "X_str_train = train.text.values\n",
    "print(len(X_str_train))\n",
    "y_train = train.label.values\n",
    "\n",
    "X_str_dev = dev.text.values\n",
    "print(len(X_str_dev))\n",
    "y_dev = dev.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "circular-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 36s, sys: 887 ms, total: 15min 37s\n",
      "Wall time: 7min 48s\n"
     ]
    }
   ],
   "source": [
    "%time X_train = [bert_classifier_phi(text) for text in X_str_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "crazy-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 36s, sys: 135 ms, total: 2min 36s\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%time X_dev = [bert_classifier_phi(text) for text in X_str_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "divine-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchShallowNeuralClassifier(\n",
    "    early_stopping=True,\n",
    "    hidden_dim=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "changing-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 47. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.8856246322393417"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.38 s, sys: 119 ms, total: 4.5 s\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "skilled-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "internal-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.924     0.926     0.925       462\n",
      "           1      0.937     0.935     0.936       541\n",
      "\n",
      "    accuracy                          0.931      1003\n",
      "   macro avg      0.931     0.931     0.931      1003\n",
      "weighted avg      0.931     0.931     0.931      1003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_dev, preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "stuffed-plumbing",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_data = pd.read_csv('tweets_mod_copy.csv')\n",
    "second_data['text'] = second_data['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "second_train, second_dev, second_test = np.split(second_data.sample(frac=1, random_state=42), [int(.8*len(second_data)), int(.9*len(second_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "behind-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "3495   How many illegal buildings should be demolishe...       0\n",
      "5461                     Whoâ€™s fatality is this tho ????       0\n",
      "9794   #OnThisDay 2018 Chinese state media confirmed ...       1\n",
      "11105  With any luck you will miss the windstorm on e...       0\n",
      "1803   Inferno on Black Friday 1939: 71 deaths, 3,700...       1\n",
      "...                                                  ...     ...\n",
      "2196   go ahead and make a playlist with your name. g...       0\n",
      "8561   Ruckelshaus, Sweeney and DDT â€“ rescued from th...       0\n",
      "11236  ðŸ˜‚We learned a long time ago why all major bank...       0\n",
      "4285   5,000 feral camels culled in drought-hit Austr...       1\n",
      "8569   Another rescued mumma koala with her little ne...       1\n",
      "\n",
      "[9096 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(second_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "spatial-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9096\n",
      "1137\n"
     ]
    }
   ],
   "source": [
    "second_X_str_train = second_train.text.values\n",
    "print(len(second_X_str_train))\n",
    "second_y_train = second_train.labels.values\n",
    "\n",
    "second_X_str_dev = second_dev.text.values\n",
    "print(len(second_X_str_dev))\n",
    "second_y_dev = second_dev.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "protecting-narrative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 56s, sys: 1.44 s, total: 23min 57s\n",
      "Wall time: 11min 58s\n"
     ]
    }
   ],
   "source": [
    "%time second_X_train = [bert_classifier_phi(text) for text in second_X_str_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "numeric-diamond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 58s, sys: 259 ms, total: 2min 58s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%time second_X_dev = [bert_classifier_phi(text) for text in second_X_str_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "residential-hometown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 17. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.3091777227818966"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.01 s, sys: 122 ms, total: 4.13 s\n",
      "Wall time: 3.57 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = model.fit(second_X_train, second_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "sophisticated-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_preds = model.predict(second_X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "informative-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     0.949     0.945       920\n",
      "           1      0.775     0.747     0.761       217\n",
      "\n",
      "    accuracy                          0.910      1137\n",
      "   macro avg      0.858     0.848     0.853      1137\n",
      "weighted avg      0.909     0.910     0.910      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_y_dev, second_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "attempted-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('real_and_fake_news.csv')\n",
    "all_data['text'] = all_data['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "relevant_data, unneeded = np.split(all_data.sample(frac=1, random_state=42), [10000])\n",
    "train, dev, test = np.split(relevant_data, [int(.8*len(relevant_data)), int(.9*len(relevant_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "abandoned-willow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "30464   Obama Announces â€˜Unfinished Businessâ€™ For 201...      0\n",
      "41926  IT BEGINSâ€¦.OBAMA APPOINTED JUDGE Rules Trump U...      0\n",
      "8877   White House says Obama will not discuss FBI pr...      1\n",
      "3798   Treasury unit to share records with Senate for...      1\n",
      "39671  HOLLYWOOD LIBS HAVE EPIC MELT DOWNSâ€¦Threaten P...      0\n",
      "...                                                  ...    ...\n",
      "22636   Republicans Dine With Trump, Then Try To Rail...      0\n",
      "2622   Trump Jr., Manafort agree to negotiate over in...      1\n",
      "6334   After 2016 campaign, more Americans consider R...      1\n",
      "1801   US Senate may vote this week to add penalties ...      1\n",
      "20427  FPL shuts one reactor in Florida, reduces powe...      1\n",
      "\n",
      "[8000 rows x 2 columns]\n",
      "                                                    text  label\n",
      "34238  WILL HILLARY ATTEND? â€˜CLOWN LIVES MATTERâ€™ Rall...      0\n",
      "13316  Bosnian Croat war criminal Praljak killed hims...      1\n",
      "14057  U.S. ally seen clinching re-election in Hondur...      1\n",
      "38775  A MUST SEE! THE BALTIMORE RIOT STORY IN ONE BI...      0\n",
      "10653  Puerto Rico needs restructuring to avoid casca...      1\n",
      "...                                                  ...    ...\n",
      "15747  Funeral of slain Malta blogger hears warning t...      1\n",
      "4068   Trump proposes 15 percent business tax rate: W...      1\n",
      "30235   Jealous Donald Trump Attacks Megyn Kelly Agai...      0\n",
      "25317   White Grievance Queen Tomi Lahren Gets OWNED ...      0\n",
      "15273  Prospects for Putin-Trump meeting at APEC summ...      1\n",
      "\n",
      "[1000 rows x 2 columns]\n",
      "                                                    text  label\n",
      "44221        What a Wonderful World â€“ US Saviour Complex      0\n",
      "25388   Obama Just OBLITERATED The GOPâ€™s Threat To Ki...      0\n",
      "22701   Trump Immediately Politicizes London Tragedy ...      0\n",
      "17542  Nigeria jails 45 Boko Haram suspects in mass t...      1\n",
      "43009  OBAMA COZIES UP TO ANOTHER COMMUNIST LEADER TO...      0\n",
      "...                                                  ...    ...\n",
      "41841  SYRIAN IMMIGRANT Who Said â€œ9-11 Changed The Wo...      0\n",
      "38962  OOPS! Lindsey Vonn Gets Hit With Big Dose Of K...      0\n",
      "9211   U.S. top court deals blow to Puerto Rico sover...      1\n",
      "19438  EU officials reach draft deal on more North Ko...      1\n",
      "2592   Trump aide Greenblatt heading to Jordan for ta...      1\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(dev)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "nuclear-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "X_str_train = train.text.values\n",
    "print(len(X_str_train))\n",
    "y_train = train.label.values\n",
    "\n",
    "X_str_dev = dev.text.values\n",
    "print(len(X_str_dev))\n",
    "y_dev = dev.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "jewish-reservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 48s, sys: 1.42 s, total: 19min 50s\n",
      "Wall time: 9min 55s\n"
     ]
    }
   ],
   "source": [
    "%time X_train = [bert_classifier_phi(text) for text in X_str_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "backed-literacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 175 ms, total: 2min 30s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%time X_dev = [bert_classifier_phi(text) for text in X_str_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "direct-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchShallowNeuralClassifier(\n",
    "    early_stopping=True,\n",
    "    hidden_dim=300,\n",
    "    hidden_activation=nn.LeakyReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "progressive-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Stopping after epoch 40. Validation score did not improve by tol=1e-05 for more than 10 epochs. Final error is 0.25402649119496346"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 108 ms, total: 5.06 s\n",
      "Wall time: 4.36 s\n"
     ]
    }
   ],
   "source": [
    "%time _ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "aerial-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "nasty-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.988     0.988     0.988       514\n",
      "           1      0.988     0.988     0.988       486\n",
      "\n",
      "    accuracy                          0.988      1000\n",
      "   macro avg      0.988     0.988     0.988      1000\n",
      "weighted avg      0.988     0.988     0.988      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_dev, preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "descending-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_data = pd.read_csv('tweets_mod_copy.csv')\n",
    "second_data['text'] = second_data['text'].apply(lambda x: re.sub(r'https?\\S+', '', x))\n",
    "second_train, second_dev, second_test = np.split(second_data.sample(frac=1, random_state=42), [int(.8*len(second_data)), int(.9*len(second_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "white-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  labels\n",
      "3495   How many illegal buildings should be demolishe...       0\n",
      "5461                     Whoâ€™s fatality is this tho ????       0\n",
      "9794   #OnThisDay 2018 Chinese state media confirmed ...       1\n",
      "11105  With any luck you will miss the windstorm on e...       0\n",
      "1803   Inferno on Black Friday 1939: 71 deaths, 3,700...       1\n",
      "...                                                  ...     ...\n",
      "2196   go ahead and make a playlist with your name. g...       0\n",
      "8561   Ruckelshaus, Sweeney and DDT â€“ rescued from th...       0\n",
      "11236  ðŸ˜‚We learned a long time ago why all major bank...       0\n",
      "4285   5,000 feral camels culled in drought-hit Austr...       1\n",
      "8569   Another rescued mumma koala with her little ne...       1\n",
      "\n",
      "[9096 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(second_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "silver-thermal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9096\n",
      "1137\n"
     ]
    }
   ],
   "source": [
    "second_X_str_train = second_train.text.values\n",
    "print(len(second_X_str_train))\n",
    "second_y_train = second_train.labels.values\n",
    "\n",
    "second_X_str_dev = second_dev.text.values\n",
    "print(len(second_X_str_dev))\n",
    "second_y_dev = second_dev.labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "italic-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 44s, sys: 1.69 s, total: 23min 46s\n",
      "Wall time: 11min 53s\n"
     ]
    }
   ],
   "source": [
    "%time second_X_train = [bert_classifier_phi(text) for text in second_X_str_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "indie-diversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 58s, sys: 196 ms, total: 2min 58s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%time second_X_dev = [bert_classifier_phi(text) for text in second_X_str_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "intelligent-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     0.949     0.945       920\n",
      "           1      0.775     0.747     0.761       217\n",
      "\n",
      "    accuracy                          0.910      1137\n",
      "   macro avg      0.858     0.848     0.853      1137\n",
      "weighted avg      0.909     0.910     0.910      1137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(second_y_dev, second_preds, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-kernel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
